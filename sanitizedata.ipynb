{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting csvfaker\n",
      "  Downloading csvfaker-1.0.5.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Faker (from csvfaker)\n",
      "  Downloading Faker-36.1.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in /Users/gunnarkleemann/opt/anaconda3/envs/bootcamp3/lib/python3.11/site-packages (from Faker->csvfaker) (2023.3)\n",
      "Downloading Faker-36.1.1-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: csvfaker\n",
      "  Building wheel for csvfaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for csvfaker: filename=csvfaker-1.0.5-py3-none-any.whl size=4117 sha256=95be09a5c05df80000e8cc78dc872c4f8da26438306bc67b3c244dabab4e90c3\n",
      "  Stored in directory: /Users/gunnarkleemann/Library/Caches/pip/wheels/1b/49/90/30b0521837019558b4ea9fc8265cec1a51847797b80f30d010\n",
      "Successfully built csvfaker\n",
      "Installing collected packages: Faker, csvfaker\n",
      "Successfully installed Faker-36.1.1 csvfaker-1.0.5\n"
     ]
    }
   ],
   "source": [
    "#worker list, change it with faker\n",
    "!pip install csvfaker --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize the Faker object\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Source', 'Target', 'Status', 'Inv_name'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Status</th>\n",
       "      <th>Inv_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acd</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acd</td>\n",
       "      <td>iqumulus</td>\n",
       "      <td>paid</td>\n",
       "      <td>08_22_acd_celenase_kh_invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acd</td>\n",
       "      <td>accelebrate</td>\n",
       "      <td>nd</td>\n",
       "      <td>accelebrate_spark materials_invoice_3 - google...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source       Target Status  \\\n",
       "0    acd           nd     nd   \n",
       "1    acd     iqumulus   paid   \n",
       "2    acd  accelebrate     nd   \n",
       "\n",
       "                                            Inv_name  \n",
       "0                                                  ?  \n",
       "1                      08_22_acd_celenase_kh_invoice  \n",
       "2  accelebrate_spark materials_invoice_3 - google...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load the data\n",
    "co_data=pd.read_csv('data_compare.csv', na_filter=False)\n",
    "#co_data=pd.read_csv('demo_companydata.csv', na_filter=False)\n",
    "\n",
    "#print(co_data.info())\n",
    "print(co_data.columns)\n",
    "co_data=co_data[['Source', 'Target', 'Status', 'Inv_name']]\n",
    "display(co_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k.martin': 'b.christopher',\n",
       " 'g.kleemann': 'g.debbie',\n",
       " 'a.martinez': 'n.benjamin',\n",
       " 'c.healey': 'a.elizabeth',\n",
       " 'g.cahal': 'j.gregory',\n",
       " 'g.mein': 'b.edward',\n",
       " 'h.jang': 'm.steve',\n",
       " 'j.ying': 'c.brian',\n",
       " 'k.kamerkar': 'p.garrett',\n",
       " 'l.matheson': 'k.dominique',\n",
       " 'l.yurica': 'j.amy',\n",
       " 'm.castro': 'n.michael',\n",
       " 'm.labowitz': 'd.hannah',\n",
       " 'm.laturney': 's.destiny',\n",
       " 'o.darwish': 'a.luis',\n",
       " 'p.denkabe': 'a.john',\n",
       " 'r.lee': 'h.victoria',\n",
       " 's.panesar': 'e.jon',\n",
       " 't.alabi': 'l.jeffrey',\n",
       " 'y.mirza': 'n.john'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'changecx': 'acme_goods', 'perl health': 'acme_goods', 'pma': 'acme_goods', 'spectre': 'change_health', 'iqumulus': 'change_health', 'grakn': 'change_health', 'rancho_biosciences': 'change_health', 't.gerbino': 'public_goods', 'family_acct': 'public_goods', 'omicia': 'mylar_co', 'webage': 'edu_analogy', 'bhanalyitcs': 'edu_analogy', 'accelebrate': 'edu_analogy', 'axcel': 'global_learning', 'data_society': 'global_learning', 'exit_certifed': 'teachers_partner', 'acd': 'austin_capital_data'}\n"
     ]
    }
   ],
   "source": [
    "workers=[\"k.martin\",\"g.kleemann\",\"a.martinez\", \"c.healey\" ,\"g.cahal\" ,\"g.mein\" ,\n",
    "    \"h.jang\" , \"j.ying\" ,\"k.kamerkar\", \"l.matheson\" , \"l.yurica\" ,\n",
    "    \"m.castro\" ,\"m.labowitz\" , \"m.laturney\" ,\n",
    "    \"o.darwish\" ,\"p.denkabe\" ,\"r.lee\" , \"s.panesar\" , \"t.alabi\" , \"y.mirza\"]\n",
    "\n",
    "fake_nameparser=lambda:((fake.name()).split()[0][0]+'.'+(fake.name()).split()[0]).lower()\n",
    "worker_remap = {wk:fake_nameparser() for wk in workers}\n",
    "display(worker_remap)\n",
    "\n",
    "remap = {'changecx': 'acme_goods', 'perl health': 'acme_goods' , 'pma': 'acme_goods',\n",
    "'spectre': 'change_health', 'iqumulus': 'change_health', 'grakn': 'change_health', \n",
    "'rancho_biosciences': 'change_health',\n",
    "'t.gerbino': \"public_goods\", 'family_acct': \"public_goods\", 'omicia': 'mylar_co',\n",
    "\"webage\": 'edu_analogy', \"bhanalyitcs\": 'edu_analogy', \"accelebrate\": 'edu_analogy',\n",
    "'axcel':'global_learning', 'data_society': 'global_learning',\n",
    "'exit_certifed' : 'teachers_partner', 'acd': 'austin_capital_data'}\n",
    "\n",
    "print(remap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_type_mappings_dict = {\"webage\":\"training_co\",\"bhanalyitcs\":\"training_co\",\"accelebrate\":\"training_co\",\n",
    "    'axcel':\"training_co\", 'data_society':\"training_co\", 'exit_certifed':\"training_co\",\n",
    "\n",
    "    'changecx':'client', 'perl health':'client', 'pma':'client', \n",
    "    'rancho_biosciences':'client','grakn':'client','iqumulus':'client',\n",
    "    'omicia':'client', 'spectre':'client',  't.gerbino':'client', 'family_acct':'client', \n",
    "\n",
    "    \"acd\":\"talent_co\",\n",
    "\n",
    "    'owner donation':'other', 'square inc o':'service','asmbly':'service',\n",
    "    '':'other','nd':'other','other':'other','na':'other',\n",
    "\n",
    "    \"k.martin\":\"worker\",\"g.kleemann\":\"worker\",\n",
    "    \"a.martinez\":\"worker\",\"c.healey\":\"worker\",\n",
    "    \"g.cahal\":\"worker\",\"g.mein\":\"worker\",\"h.jang\":\"worker\",\n",
    "    \"j.ying\":\"worker\",\"k.kamerkar\":\"worker\",\n",
    "    \"l.matheson\":\"worker\",\"l.yurica\":\"worker\",\"m.castro\":\"worker\",\n",
    "    \"m.labowitz\":\"worker\",\"m.laturney\":\"worker\",\"o.darwish\":\"worker\",\n",
    "    \"p.denkabe\":\"worker\",\"r.lee\":\"worker\",\"s.panesar\":\"worker\",\n",
    "    \"t.alabi\":\"worker\",\"y.mirza\":\"worker\" \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_replace_dict(data, find, replace):\n",
    "    new_dict = {}\n",
    "    for key, value in data.items():\n",
    "        new_key = key.replace(find, replace) if isinstance(key, str) else key\n",
    "        new_value = value.replace(find, replace) if isinstance(value, str) else value\n",
    "        new_dict[new_key] = new_value\n",
    "    return new_dict\n",
    "\n",
    "# my_dict = {\"apple pie\": \"apple filling\", \"banana bread\": \"banana mush\"}\n",
    "# find_string = \"apple\"\n",
    "# replace_string = \"orange\"\n",
    "\n",
    "# updated_dict = find_and_replace_dict(my_dict, find_string, replace_string)\n",
    "# print(updated_dict)\n",
    "# # Expected output: {'orange pie': 'orange filling', 'banana bread': 'banana mush'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edu_analogy': 'training_co', 'global_learning': 'training_co', 'teachers_partner': 'training_co', 'acme_goods': 'client', 'change_health': 'client', 'mylar_co': 'client', 'public_goods': 'client', 'austin_capital_data': 'talent_co', 'owner donation': 'other', 'square inc o': 'service', 'asmbly': 'service', '': 'other', 'nd': 'other', 'other': 'other', 'na': 'other', 'b.christopher': 'worker', 'g.debbie': 'worker', 'n.benjamin': 'worker', 'a.elizabeth': 'worker', 'j.gregory': 'worker', 'b.edward': 'worker', 'm.steve': 'worker', 'c.brian': 'worker', 'p.garrett': 'worker', 'k.dominique': 'worker', 'j.amy': 'worker', 'n.michael': 'worker', 'd.hannah': 'worker', 's.destiny': 'worker', 'a.luis': 'worker', 'a.john': 'worker', 'h.victoria': 'worker', 'e.jon': 'worker', 'l.jeffrey': 'worker', 'n.john': 'worker'}\n"
     ]
    }
   ],
   "source": [
    "# update the entity structure\n",
    "updated_dict=entity_type_mappings_dict.copy()\n",
    "\n",
    "for k in remap:\n",
    "    updated_dict = find_and_replace_dict(updated_dict, k, remap[k])\n",
    "#print(updated_dict)\n",
    "\n",
    "for k in worker_remap:\n",
    "    updated_dict = find_and_replace_dict(updated_dict, k, worker_remap[k])\n",
    "print(updated_dict)\n",
    "\n",
    "\n",
    "# df_replaced = replace_strings_dict(df.copy(), 'col1', replacement_dict)\n",
    "# print(\"DataFrame with 'col1' replaced:\\n\", df_replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modified data frame'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Status</th>\n",
       "      <th>Inv_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>nd</td>\n",
       "      <td>nd</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>change_health</td>\n",
       "      <td>paid</td>\n",
       "      <td>08_22_acd_celenase_kh_invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>edu_analogy</td>\n",
       "      <td>nd</td>\n",
       "      <td>accelebrate_spark materials_invoice_3 - google...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>edu_analogy</td>\n",
       "      <td>nd</td>\n",
       "      <td>accelebrate_spark materials_invoice_4_update.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>edu_analogy</td>\n",
       "      <td>nd</td>\n",
       "      <td>accelebrate_spark_invoice_4.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>n.john</td>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>paid</td>\n",
       "      <td>ymirza_11112_feb_24-2/25/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>n.john</td>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>paid</td>\n",
       "      <td>ymirza_11116_augment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>n.john</td>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>paid</td>\n",
       "      <td>ymirza_12_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>n.john</td>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>void</td>\n",
       "      <td>ymirza_x_mar_24-3/25/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>austin_capital_data</td>\n",
       "      <td>asmbly</td>\n",
       "      <td>paid</td>\n",
       "      <td>zelle payment from asmbly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Source               Target Status  \\\n",
       "0    austin_capital_data                   nd     nd   \n",
       "1    austin_capital_data        change_health   paid   \n",
       "2    austin_capital_data          edu_analogy     nd   \n",
       "3    austin_capital_data          edu_analogy     nd   \n",
       "4    austin_capital_data          edu_analogy     nd   \n",
       "..                   ...                  ...    ...   \n",
       "375               n.john  austin_capital_data   paid   \n",
       "376               n.john  austin_capital_data   paid   \n",
       "377               n.john  austin_capital_data   paid   \n",
       "378               n.john  austin_capital_data   void   \n",
       "379  austin_capital_data               asmbly   paid   \n",
       "\n",
       "                                              Inv_name  \n",
       "0                                                    ?  \n",
       "1                        08_22_acd_celenase_kh_invoice  \n",
       "2    accelebrate_spark materials_invoice_3 - google...  \n",
       "3     accelebrate_spark materials_invoice_4_update.pdf  \n",
       "4                      accelebrate_spark_invoice_4.pdf  \n",
       "..                                                 ...  \n",
       "375                        ymirza_11112_feb_24-2/25/24  \n",
       "376                               ymirza_11116_augment  \n",
       "377                                       ymirza_12_23  \n",
       "378                            ymirza_x_mar_24-3/25/24  \n",
       "379                          zelle payment from asmbly  \n",
       "\n",
       "[380 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=co_data.copy()\n",
    "\n",
    "for col in ['Source', 'Target']:\n",
    "    df[col] = df[col].replace(remap, regex=False)\n",
    "    df[col] = df[col].replace(worker_remap, regex=False)\n",
    "display('modified data frame', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save or load the main data.\n",
    "df.to_csv('demo_companydata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "\n",
    "https://www.dennisokeeffe.com/blog/2021-08-11-generating-fake-csv-data-with-python\n",
    "\n",
    "https://medium.com/@Shamimw/generating-fake-data-csv-json-parquet-using-python-db640a369a6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (851526181.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    https://www.dennisokeeffe.com/blog/2021-08-11-generating-fake-csv-data-with-python\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
